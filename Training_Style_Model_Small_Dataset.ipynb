{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!time ./setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source activate tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data smaller\n",
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "for filename in glob('data/train2014/*'):\n",
    "    if random.random() > 0.025: # use only 2.5% of the data\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn art style: train model\n",
    "# upload steampunk image\n",
    "!time python style.py --style ../steampunk.jpg --checkpoint-dir checkpoint --epochs 2 --checkpoint-iterations 10 --batch-size 16\n",
    "#!nvidia-smi # read \"Disp.A Memory-Usage: and \"GPU Memory Usage\" for how much GPU RAM usage; \"Volatile GPU-Util\" grossly inaccurate\n",
    "!pip install glances # glances is way better than nvidia-smi in terms of accuracy and UI\n",
    "!pip install nvidia-ml-py3\n",
    "!glances\n",
    "# remove test-dir and other parameters for now\n",
    "\n",
    "# use small batches if training pictures are bigger\n",
    "\n",
    "\n",
    "\n",
    "# on 2.5% of pictures and 16 minibatch:\n",
    "# real    9m59.879s\n",
    "# user    9m5.264s\n",
    "# sys     0m48.336s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir test_dir\n",
    "!time python style.py --style ../steampunk.jpg --checkpoint-dir checkpoint --epochs 2 --checkpoint-iterations 10 --batch-size 16 --test examples/style/rain_princess.jpg --test-dir test_dir\n",
    "\n",
    "## complete runtime here\n",
    "## appears that it will regress to black; maybe GPU RAM constrained?\n",
    "## also uses CPU by default, I changed it to be GPU, don't know if RAM is constrained. Have to make this argparse\n",
    "\n",
    "# every iteration causes checkpoint save (GPU not running) and inference on test image, so use high iteration number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply style on another picture, compare CPU vs GPU\n",
    "# I don't think there are any other important parameters\n",
    "!time python evaluate.py --checkpoint checkpoint --in-path examples/style/rain_princess.jpg --out-path ../output_image.jpg\n",
    "\n",
    "# about the same between GPU (slightly faster) and CPU\n",
    "# real    0m5.287s\n",
    "# user    0m3.556s\n",
    "# sys     0m2.068s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply style to video\n",
    "# upload video: play_dead.mp4\n",
    "# use smaller minibatch if video very high resolution\n",
    "!time python transform_video.py --in-path ../play_dead.mp4   --checkpoint checkpoint   --out-path ../output_video.mp4   --device /gpu:0   --batch-size 16\n",
    "\n",
    "# GPU\n",
    "# real    0m19.682s\n",
    "# user    0m22.548s\n",
    "# sys     0m6.408s\n",
    "\n",
    "# CPU\n",
    "# real    5m50.725s\n",
    "# user    21m21.868s\n",
    "# sys     1m17.100s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the first part to GPU to reduce runtime by 22 seconds\n",
    "\n",
    "# Speed\n",
    "## Try:  more GPUs\n",
    "## Done: bigger minibatch, less pictures\n",
    "\n",
    "# Quality:\n",
    "## Try: increase style weight, increase learning rate\n",
    "## Done: add test folder\n",
    "\n",
    "# Notes:\n",
    "## notice with more iterations, then color of original image more visible; I assume that means the content loss is being reduced\n",
    "## GPU RAM is full on this EC2 instance by loading up model. Thank goodness it fits into memory! For more powerful GPU, can probably increase minibatch for evaluation\n",
    "## Currently GPU RAM constrained; not sure how it's evaluating testing picture without sufficient GPU RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--style, --checkpoint-dir # explicitly required\n",
    "--train-path, --vgg-path # implicitly required\n",
    "\n",
    "--epochs, --checkpoint-iterations, --batch-size, # optional\n",
    "--test, --test-dir, --content-weight, --style-weight, --tv-weight, --learning-rate # more optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.video.VideoClip import VideoClip\n",
    "\n",
    "clip = VideoFileClip('play_dead.mp4')\n",
    "cropped = clip.crop(x1=0, y1=0, x2=100, y2=200)\n",
    "cropped.write_videofile('cropped_video.mp4') # what are dimensions? consider amount of time\n",
    "\n",
    "# can do the same with ffmpeg and openCV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
