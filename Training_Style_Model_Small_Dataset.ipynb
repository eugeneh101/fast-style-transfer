{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!time ./setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source activate tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data smaller\n",
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "for filename in glob('data/train2014/*'):\n",
    "    if random.random() > 0.025: # use only 2.5% of the data\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn art style: train model\n",
    "# upload steampunk image\n",
    "!time python style.py --style ../steampunk.jpg --checkpoint-dir checkpoint --epochs 2 --checkpoint-iterations 10 --batch-size 16\n",
    "!nvidia-smi # read \"Disp.A Memory-Usage: and \"GPU Memory Usage\" for how much GPU RAM usage; \"Volatile GPU-Util\" grossly inaccurate\n",
    "# remove test-dir and other parameters for now\n",
    "# use small batches if training pictures are bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply style on another picture, compare CPU vs GPU\n",
    "# I don't think there are any other important parameters\n",
    "!time python evaluate.py --checkpoint checkpoint --in-path examples/style/rain_princess.jpg --out-path ../output_image.jpg\n",
    "\n",
    "# on 2.5% of pictures and 16 minibatch:\n",
    "# real    10m16.101s\n",
    "# user    9m56.076s\n",
    "# sys     0m50.824s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply style to video\n",
    "# upload video: play_dead.mp4\n",
    "# use smaller minibatch if video very high resolution\n",
    "!time python transform_video.py --in-path ../play_dead.mp4   --checkpoint checkpoint   --out-path ../output_video.mp4   --device /gpu:0   --batch-size 16\n",
    "\n",
    "# real    0m22.354s\n",
    "# user    0m22.828s\n",
    "# sys     0m6.864s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed\n",
    "## Try:  more GPUs\n",
    "## Done: bigger minibatch, less pictures\n",
    "\n",
    "# Quality:\n",
    "## try: increase style weight, increase learning rate, add test folder\n",
    "\n",
    "# Notes:\n",
    "## notice with more iterations, then color of original image more visible\n",
    "## GPU RAM is full on this EC2 instance by loading up model. Thank goodness it fits into memory! For more powerful GPU, can probably increase minibatch for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--style, --checkpoint-dir # explicitly required\n",
    "--train-path, --vgg-path # implicitly required\n",
    "\n",
    "--epochs, --checkpoint-iterations, --batch-size,# optional\n",
    "--test, --test-dir, --content-weight, --style-weight, --tv-weight, --learning-rate # more optional"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
