{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find conda environment: tensorflow-gpu\r\n",
      "You can list all discoverable environments with `conda info --envs`.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!source activate tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glances/htop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git pull repo\n",
    "upload some pictures\n",
    "source activate\n",
    "mkdir test_dir\n",
    "mkdir test_dir/checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time python style.py --style examples/style/rain_princess.jpg  \\\n",
    "    --checkpoint-dir checkpoint/checkpoints/ --checkpoint-iterations 5 \\\n",
    "    --test examples/style/udnie.jpg  --test-dir checkpoint/ \\\n",
    "    --batch-size 20 --device /gpu:0 --content-weight 1.2e1 \\\n",
    "    &> checkpoint/runtime.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python style.py --style ../styles/wave.jpg \\\n",
    "    --checkpoint-dir test_dir_wave_1_GPU/checkpoint_wave/ --checkpoint-iterations 50 \\\n",
    "    --test ../input_images/stata_modified.jpg --test-dir test_dir_wave_1_GPU/ \\\n",
    "    --batch-size 20 --device /gpu:0 --content-weight 1.2e1 \\\n",
    "    &> test_dir_wave_1_GPU/runtime_wave.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time python style.py --style examples/style/rain_princess.jpg \\\n",
    "    --checkpoint-dir checkpoint/checkpoints/ --checkpoint-iterations 50 --batch-size 20 --device /gpu:0 \\\n",
    "    --test examples/style/udnie.jpg \\\n",
    "    &> checkpoint/runtime.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time python style.py --style ../styles/wave.jpg \\\n",
    "    --checkpoint-dir test_dir_wave_1_GPU/checkpoint_wave/ --checkpoint-iterations 50 \\\n",
    "    --test ../input_images/stata_modified.jpg --test-dir test_dir_wave_1_GPU/ \\\n",
    "    --batch-size 20 --device /gpu:0 --content-weight 1.2e1 \\\n",
    "    &> test_dir_wave_1_GPU/runtime_wave.txt\n",
    "\n",
    "time python style.py --style ../styles/wave.jpg \\\n",
    "    --checkpoint-dir test_dir_wave_1_CPU/checkpoint_wave/ --checkpoint-iterations 5 \\\n",
    "    --test ../input_images/stata_modified.jpg --test-dir test_dir_wave_1_CPU/ \\\n",
    "    --batch-size 20 --device /cpu:1 --content-weight 1.2e1 \\\n",
    "    &> test_dir_wave_1_CPU/runtime_wave.txt\n",
    "\n",
    "time python style.py --style ../styles/wave.jpg \\\n",
    "    --checkpoint-dir test_dir_wave_32_CPU/checkpoint_wave/ --checkpoint-iterations 5 \\\n",
    "    --test ../input_images/stata_modified.jpg --test-dir test_dir_wave_32_CPU/ \\\n",
    "    --batch-size 20 --device /cpu:30 --content-weight 1.2e1 \\\n",
    "    &> test_dir_wave_32_CPU/runtime_wave.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture\n",
    "test_dir\n",
    "test_image; test_dir\n",
    "GPU number\n",
    "runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blank Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time python style.py --style ../styles/starry_night_by_van_gogh.jpg \\\n",
    "    --checkpoint-dir test_dir_blank/checkpoint_blank/ --checkpoint-iterations 1 \\\n",
    "    --test ../input_images/beach_palm.jpg --test-dir test_dir_blank/ \\\n",
    "    --batch-size 1 --device /cpu:30 \\\n",
    "    &> test_dir_blank/runtime_blank.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time python style.py --style ../styles/wave.jpg \\\n",
    "    --checkpoint-dir test_dir_blank/checkpoint_blank/ --checkpoint-iterations 1 \\\n",
    "    --test ../input_images/stata_modified.jpg --test-dir test_dir_blank/ \\\n",
    "    --batch-size 1 --device /cpu:30 \\\n",
    "    &> test_dir_blank/runtime_blank.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is big evaluation time differences between pictures of same shape vs pictures of different shape. \n",
    "# Same shape evaluates much faster than different shape.\n",
    "# It appears that GPU also uses noticeable amounts of CPU.\n",
    "# CPU currently evalutes using all CPUs, not 1 CPU. Hence, the ratio would be suspectible to number of CPUs.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do you want to save the models so you can immediately apply style transfer on known style?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import OrderedDict\n",
    "\n",
    "def get_structured_data(data):\n",
    "    key_value_tups = (OrderedDict(element.split(' = ') for element in line.split('; ')) for line in data)\n",
    "    return pd.DataFrame(key_value_tups)\n",
    "\n",
    "with open('test_dir_replicate/runtime_replicate.txt') as f: ## hard coded file name\n",
    "    data = f.read().splitlines()\n",
    "    useful_data = [line for line in data if 'Current Time' in line]\n",
    "    structured_data = get_structured_data(useful_data)\n",
    "    structured_data[['Epoch', 'Iteration']] = structured_data[['Epoch', 'Iteration']].astype('int')\n",
    "    structured_data[['Loss', 'Time Elapsed']] = structured_data[['Loss', 'Time Elapsed']].astype('float32')\n",
    "    structured_data.set_index(structured_data.index * 50, inplace=True) ### hard coded to 50 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_data['Time Elapsed'].cumsum().plot(title=\"Time vs Iteration\", marker='o', linestyle='None')\n",
    "plt.show()\n",
    "structured_data['Loss'].plot(logy=True, title='Logged Loss over Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "with open('test_dir_replicate/runtime_replicate.txt') as f: ## hard coded file name\n",
    "    data = f.read().splitlines()\n",
    "    useful_lines = [line for line in data if \"Loss values\" in line]\n",
    "    key_value_tups = (OrderedDict(element.split(' = ') for element in line.replace(\"Loss values: \", \"\").split('; '))\n",
    "                      for line in useful_lines)\n",
    "    structured_data_loss = pd.DataFrame(key_value_tups).astype('float')\n",
    "    structured_data_loss.set_index(structured_data_loss.index * 50, inplace=True) ### hard coded to 50 iterations\n",
    "\n",
    "structured_data_loss.plot(logy=True)\n",
    "structured_data_loss.sum(axis=1).plot(logy=True, label='Total loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_data['Loss'][5:].plot()\n",
    "plt.show()\n",
    "\n",
    "structured_data_loss['style'][5:].plot()\n",
    "structured_data_loss['content'][5:].plot()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write script to detect new model and rename it to keep it from being overwritten\n",
    "possible for styel to be applied to video but that's more work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import imageio\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "seconds_between_frames = 30 # represents seconds of time for training\n",
    "max_length_in_seconds = 60 * 60 * 5 ## hard coded to represent maximum length of training time\n",
    "test_dirname = 'test_dir_replicate/' ### hard coded\n",
    "output_filename = test_dirname + 'movie.mp4'\n",
    "\n",
    "image_filenames = []\n",
    "next_frame_timestamp = None\n",
    "for row_id, row in structured_data.iterrows():\n",
    "    if row_id == 0:\n",
    "        start_time = (datetime.strptime(row['Current Time'], \"%Y %B %d, %H:%M:%S\") -\n",
    "                      timedelta(seconds=int(row['Time Elapsed'])))\n",
    "        next_frame_timestamp = start_time\n",
    "        while next_frame_timestamp < datetime.strptime(row['Current Time'], \"%Y %B %d, %H:%M:%S\"):\n",
    "            image_filenames.append(\"{}{}_{}.png\".format(test_dirname, row['Epoch'], row['Iteration']))\n",
    "            next_frame_timestamp += timedelta(seconds=seconds_between_frames)\n",
    "            \n",
    "    else:\n",
    "        while next_frame_timestamp < datetime.strptime(row['Current Time'], \"%Y %B %d, %H:%M:%S\"):\n",
    "            image_filenames.append(\"{}{}_{}.png\".format(test_dirname, row['Epoch'], row['Iteration']))\n",
    "            next_frame_timestamp += timedelta(seconds=seconds_between_frames)        \n",
    "        \n",
    "image_sequence = []\n",
    "for filename in image_filenames[:max_length_in_seconds // seconds_between_frames]:\n",
    "    image_sequence.append(imageio.imread(filename))\n",
    "imageio.mimsave(output_filename, image_sequence, fps=24) ### fps hard coded\n",
    "\n",
    "\"\"\"\n",
    "import imageio\n",
    "\n",
    "sorted_frame_names = 'test_dir_replicate/' + structured_data.apply(\n",
    "    lambda row: \"{}_{}.png\".format(row['Epoch'], row['Iteration']), axis=1) # test_dir hard coded\n",
    "images = []\n",
    "for filename in sorted_frame_names:\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave('test_dir_replicate/movie.mp4', images, fps=2) ### fps hard coded\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how about many known styles and then create a grid of transformed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideally a simple web app to upload a picture and watch the style transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "there's crop video and stitch video code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "(ffmpeg\n",
    "    .input(input_video_path)\n",
    "    .crop(x1, y1, x_delta, y_delta) # this requires left upper corner and deltas\n",
    "    .output(output_video_path)\n",
    "    .run()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mpe\n",
    "video_width, video_height = mpe.VideoFileClip(input_video_path).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import ffmpeg\n",
    "import moviepy.editor as mpe\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def crop_video(input_video_path, ith_video, jth_horizontal_partition, \n",
    "        kth_vertical_partition, num_horizontal_partitions, num_vertical_partitions):    \n",
    "    video_dir = os.path.dirname(input_video_path)\n",
    "    video_filename = os.path.basename(input_video_path)\n",
    "    \n",
    "    video_width, video_height = mpe.VideoFileClip(input_video_path).size\n",
    "    y_delta = int(video_height / num_horizontal_partitions)\n",
    "    x_delta = int(video_width / num_vertical_partitions)\n",
    "    x1 = kth_vertical_partition * x_delta\n",
    "    y1 = jth_horizontal_partition * y_delta\n",
    "\n",
    "    output_video = '{}_{}'.format(ith_video, video_filename)\n",
    "    output_video_path = os.path.join(video_dir, output_video)\n",
    "    if os.path.isfile(output_video_path):\n",
    "        os.remove(output_video_path)\n",
    "    (ffmpeg\n",
    "        .input(input_video_path)\n",
    "        .crop(x1, y1, x_delta, y_delta) # this requires left upper corner and deltas\n",
    "        .output(output_video_path)\n",
    "        .run()\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_horizontal_partitions = 2 ### define here\n",
    "    num_vertical_partitions = 2 ### define here\n",
    "    input_video_path = '../input_video/play_dead.mp4' ### define here\n",
    "\n",
    "    ith_video = 0\n",
    "    for jth_horizontal_partition in range(num_horizontal_partitions):\n",
    "        for kth_vertical_partition in range(num_vertical_partitions):\n",
    "            crop_video(input_video_path, ith_video, \n",
    "                       jth_horizontal_partition, kth_vertical_partition, \n",
    "                       num_horizontal_partitions, num_vertical_partitions)\n",
    "            ith_video += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
